---
output: 
  revealjs::revealjs_presentation:
    css: style1.css
    self_contained: false
    reveal_plugins: ["zoom"]
    transition: fade
    mathjax: "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS_SVG"
    reveal_options:
      width: "90%"
      height: "100%"
      minScale: 1
      maxScale: 1
      slideNumber: false
      controls: false
      progress: false
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F, error = F)
```

```{r, echo = F}
library(ggplot2)
library(dplyr)
library(cowplot)
library(extrafont)
library(tidyverse)
library(magick)
bg_col <- "#ac3939"
theme_set(
  theme_bw() + 
    theme(plot.background = element_rect(fill = bg_col, color = bg_col),
          legend.box.background = element_rect(color = "black"), 
          axis.text = element_text(color = "white"),
          axis.title = element_text(color = "white"))
)
```

## 

::: {style="position:absolute;width:80%;height:500px;border: 0px double;padding: 50px 10px; left:10%; top:20px;"}
::: {style="position:absolute;width:500px;top:200px;"}
<img src="fig/2bees_opaque.png" width="400" height="400" style="border:4px solid; border-radius:100%; padding:0px;display:block;margin-left:auto;margin-right:auto"/>

::: {style="font-size:0.25em;position:absolute;right:0px;"}
Illustration: Amrei Binzer-Panchal
:::
:::

::: {style="position:absolute;text-align:left; font-size: 1.5em;padding:50px;left:500px;width:50%;"}
<br>

::: {style="font-size:0.5em"}
Basic Biostatistics and Bioinformatics
:::

Common statistical tests

::: {style="font-size:0.5em"}
Swedish University of Agricultural Sciences, Alnarp
:::

::: {style="font-size:0.3em"}
<br>10 March 2025
:::
:::
:::

## Basic Biostatistics and Bioinformatics

A seminar series on the fundamentals

Organised by *SLUBI* and *Statistics at SLU*

Presentation of background and a practical exercise

<br>

Topic suggestions are welcome

## 

**SLUBI**

-   SLU bioinformatics center
-   Weekly online drop-in (Wednesdays at 13.00)
-   [slubi\@slu.se](mailto:slubi@slu.se){.email}, <https://www.slubi.se>
-   Alnarp: Lizel Potgieter (Dept. of Plant Breeding)

<br>

**Statistics at SLU**

-   SLU statistics center
-   Free consultations for all SLU staff
-   [statistics\@slu.se](mailto:statistics@slu.se){.email}
-   Alnarp: Jan-Eric Englund and Adam Flöhr (Dept. of Biosystems and Technology)

## Today

Some fundamental ideas

Type of response variable

Type of explanatory variable(s)

Method of data collection

Linear models as a unifying approach

# Fundamental ideas

Simplification for the sake of generalization

<br>

Descriptive

- Summarizing collected data

Inferential

- Tests to identify underlying patterns

Predictive

- Projecting to non-observed cases

## Population to sample

<div style="width:70%;">
We generalize to some *population* of individual units

Seldom possible to observe full population

<div class="fragment fade-in">
Draw a subset of individuals (a *sample*)
</div>

<div class="fragment fade-in">
This sampling has some randomness too it
</div>

<div class="fragment fade-in">
but given some assumptions about the population and the method of drawing a sample, we know what the sample *should* look like
</div>
</div>

<div style="width:30%;float:right;left:1200px;top:100px;position:absolute;">
```{r, echo = F, fig.height=6, fig.width = 4}
dat <- data.frame(t = seq(0, 2*pi, length.out = 1000)) %>% 
  mutate(x = cos(t), y = sin(t))
dat_arrow <- data.frame(c = rep(1:3, each = 2),
                        x1 = c(-1 + 0.1, 0, 1 - 0.1),
                        x2 = c(-2/3 + 0.1, 0, 2/3 - 0.1),
                        y1 = c(0,-1 + 0.1, 0),
                        y2 = c(-2,2/3 - 2 - 0.1, -2))

ggplot(dat) +
  geom_polygon(aes(x, y), fill = "#fcc2ff", col = "black") +
  geom_polygon(aes(x / 1.5, y / 1.5 - 2), fill = "#bffcc6", col = "black") +
  geom_segment(aes(x1, y1, xend = x2, yend = y2), data = dat_arrow, 
               arrow = arrow(length = unit(0.30,"cm"), type = "closed")) +
  annotate("text", 0, 0, label = "Population", size = 8, family = "Garamond") +
  annotate("text", 0, -2, label = "Sample", size = 8, family = "Garamond") +
  theme_nothing() +
  theme(panel.background = element_rect(fill = bg_col, color = bg_col),
        plot.background = element_rect(fill = bg_col, color = bg_col)) +
  ylim(-3,1)
```
</div>

## Sample to test

<div style="width:70%;">
This population-sample setup is the basis of null hypothesis significance testing

<br>

<div class="fragment fade-in">
Assume a certain population property (a *null hypothesis*)
</div>

<div class="fragment fade-in">
Calculate the probability of getting the observed sample if that hypothesis is true (a *p-value*)
</div>

<div class="fragment fade-in">
If that probability is small, the null hypothesis is assumed false (a *significant result*)
</div>
</div>

<div style="width:30%;float:right;left:1200px;top:100px;position:absolute;">
```{r, echo = F, fig.height=6, fig.width = 4}
dat <- data.frame(t = seq(0, 2*pi, length.out = 1000)) %>% 
  mutate(x = cos(t), y = sin(t))
dat_arrow <- data.frame(c = rep(1:3, each = 2),
                        x1 = c(-1 + 0.1, 0, 1 - 0.1),
                        x2 = c(-2/3 + 0.1, 0, 2/3 - 0.1),
                        y1 = c(0,-1 + 0.1, 0),
                        y2 = c(-2,2/3 - 2 - 0.1, -2))

ggplot(dat) +
  geom_polygon(aes(x, y), fill = "#fcc2ff", col = "black") +
  geom_polygon(aes(x / 1.5, y / 1.5 - 2), fill = "#bffcc6", col = "black") +
  geom_segment(aes(x1, y1, xend = x2, yend = y2), data = dat_arrow, 
               arrow = arrow(length = unit(0.30,"cm"), type = "closed")) +
  annotate("text", 0, 0, label = "Population", size = 8, family = "Garamond") +
  annotate("text", 0, -2, label = "Sample", size = 8, family = "Garamond") +
  theme_nothing() +
  theme(panel.background = element_rect(fill = bg_col, color = bg_col),
        plot.background = element_rect(fill = bg_col, color = bg_col)) +
  ylim(-3,1)
```
</div>

## Choice of model/test

NHST is a general setup for inference

The exact type of test depends on the situation

<br>

Three main components

- Type of response variable

- Type of explanatory variables

- Method of data collection

# Type of response variable

The response variable is whatever property we are measuring

<br>

Two connected matters

- The type of variable

- The distribution of the outcomes

## Some typical categorisations

Quantitative or qualitative

- Quantitative: numerical
- Qualitative: non-numerical

<div class="fragment fade-in">
Discrete or continuous numerical variables

- Discrete: subset of numbers as possible outcomes
  - Typically whole numbers (1, 2, 3 etc)
- Continuous: any decimal number is a possible outcome
</div>

<div class="fragment fade-in">
Type of outcome

- Binary variables. Two possible outcomes
- Proportions. Outcomes between zero and one
  - Discrete case: number of successes of a total
  - Continuous case: any number in the 0-to-1-range
</div>

## Measurements of scale 

Also known as Stevens' typology

<div class="fragment fade-in">
- Nominal
  - *Names.* Outcomes in categories
  - Two outcomes are either equal or different
</div>
<div class="fragment fade-in">
- Ordinal
  - *Order.* Outcomes in ordered categories
  - One outcome is smaller, equal or greater than another
</div>
<div class="fragment fade-in">
- Interval
  - Numerical outcome
  - The difference between two outcomes is meaningful
</div>
<div class="fragment fade-in">
- Ratio
  - Numerical outcome
  - The ratio of two outcomes is meaningful
</div>

## Distributions

The observations have some random variation

This randomness can be expressed with a probability distribution

The distribution assigns a probability for each possible outcome

<br>
<div class="fragment fade-in">
Distributions depend on *parameters*, estimated from collected data

```{r, fig.width=5, fig.height=4, fig.align='center'}
dat_norm <- tibble(x = seq(-4,4,0.1), y_c = dnorm(x))

ggplot(dat_norm) +
  geom_line(aes(x, y_c)) +
  scale_x_continuous(breaks = -1:1, labels = c("μ - σ", "μ", "μ + σ")) +
  theme(axis.title = element_blank(), text = element_text(family = "serif", size = 15, color = "white"),
        axis.text = element_text(family = "serif", color = "white"),
        axis.ticks = element_line(color = "white"),
        panel.grid = element_blank())
```
</div>

##

The type of distribution depends on the type of variable

|Variable type      |Scale                   |Common distribution     |
|-------------------|------------------------|------------------------|
|Continuous numeric |Interval, ratio         |Normal distribution     |
|Discrete numeric   |Interval, ratio         |Poisson distribution    |
|Binary             |Nominal                 |Bernoulli distribution  |
|Discrete proportion|Interval, ratio         |Binomial distribution   |
|Categorical        |Nominal, ordinal        |*Ad-hoc* distributions  |

<br>

```{r, echo=F, fig.height=4, fig.width=14, fig.align='center'}
dat_dist <- tibble(type = "Continuous numeric\nNormal",
                   x = seq(-4,4,0.1),
                   y_c = dnorm(x)) %>% 
  bind_rows(tibble(type = "Binary\nBernoulli",
            x = 0:1, y_d = c(0.3,0.7))) %>% 
  bind_rows(tibble(type = "Discrete numeric\nPoisson",
            x = 0:10, y_d = dpois(x, 3.4))) %>% 
  bind_rows(tibble(type = "Proportion (discrete)\nBinomial",
                   x = 0:5, y_d = dbinom(x, 5, 0.3)))

dat_dist %>% 
  ggplot() +
  geom_col(aes(x, y_d), width = 0.6) +
  geom_line(aes(x, y_c)) +
  facet_wrap(~ type, scales = "free", ncol = 4) +
  scale_x_continuous(breaks = -10:10) +
  theme(axis.title = element_blank(), text = element_text(family = "serif", size = 15, color = "white"),
        axis.text = element_text(family = "serif", color = "white"),
        axis.ticks = element_line(color = "white"),
        panel.grid = element_blank())
```

# Type of explanatory variable

The scientific question is typically to see how the response *depends* on another variable

Often called the *explanatory* or *independent* variable

<div class="fragment fade-in">
Two distinct cases

- Categorical explanatory variable
  - The explanatory variable specifies a group
  - Want to test for a group difference
  - Test choice depends on number of groups
</div>
<div class="fragment fade-in">
- Numerical explanatory variable
  - Want to test for a connection between explanatory variables and response variables
</div>

# Data collection

Test choice also depends on the method of data collection

Most fundamental tests assume observations are independent random draws from the population

<br>
<div class="fragment fade-in">
When comparing two treatment groups the data is often in *paired observations*

The observational units are divided into pairs and each treatment group is used once
</div>
<br>
<div class="fragment fade-in">
This generalizes to multiple groups as *blocks*

The observational units are divided into blocks and each treatment group is used once per block
</div>

## Observational units and pseudo-replicates

Another common collection trait is multiple observation on the same observational unit

- Multiple leafs from a plant
- Multiple soil samples from the same treatment plot
- Technical replicates of the same biological sample

<div class="fragment fade-in">
This will result in non-independent observations

Sometimes referred to as pseudo-replicates

One can aggregate by taking the average (mean)
</div>

# Choice of test

We get different test for different situations

The setup is always the same:

- The null hypothesis is that there are no differences / no connections between variables
- The p-value captures the probability of the observed data if that null is true
- A low p-value gives rejection of the null

<div class="fragment fade-in">
In the background a *test-value* is calculated and the p-value is based on that value following a specific *test-distribution*

Tests are typically named after that distribution (t-tests, F-tests, $\chi^2$-tests) or after an early user of the test
</div>

## Table of basic tests

```{r, eval=FALSE, echo=FALSE}
tab_test <- tibble("Response \\ Explanatory" = c("Nominal", "Ordinal", "Interval/Ratio", "Binary", "Non-parametric"),
                   Categorical = c("$\\chi^2$", "$\\chi^2$", "t-test", "$\\chi^2$- or z-test", "Kruskal-Wallis"),
                   Numerical = c("X", "X", "Correlation or regression", "X", "Spearman correlation"))
```

|Response \\ Explanatory |Categorical         |Numerical                    |
|:-----------------------|:-------------------|:----------------------------|
|Nominal                 |$\chi^2$            |(Nominal regression)         |
|Ordinal                 |$\chi^2$            |(Ordinal regression)         |
|Binary                  |$\chi^2$- or z-test |(Binary/logistic regression) |
|Interval/Ratio          |t-test or F-test    |Correlation or regression    |
|Non-parametric          |Kruskal-Wallis      |Spearman correlation         |

Cases in brackets are not common introductory material

<br>
It is also possible to see the t-test (or F-test) for ordinal or non-normal numerical responses

This can be justified by the *central limit theorem*

## Example data

We can create some random data in R

Three different explanatory variables

- one grouping with 2 levels,
- one grouping with 4 levels,
- and one numerical

Three different response variables: 

- a nominal response, 
- a binary response, 
- and a numeric response

##

```{r, echo = T}
library(tidyverse)
set.seed(250310)
dat <- tibble(group_1 = rep(c("A","B"), each = 40),
              group_2 = rep(c("a", "b", "c", "d"), each = 20),
              numeric_explanatory = runif(80),
              nominal_response = sample(c("a", "b", "c"), 80, replace = T),
              binary_response = sample(c("a", "b"), 80, replace = T),
              numeric_response = rnorm(80) + (group_1 == "A") + numeric_explanatory)
dat
```

## Nominal or ordinal response

<div style="width:30%;float:right;font-size:0.5em;">
```{r, echo = T, fig.height=4, fig.width = 4}
ggplot(dat, aes(group_2, fill = nominal_response)) +
  geom_bar(color = "black")
```
</div>

<div style="width:70%;">
**Categorical explanatory**

Connection between variables can be tested with a $\chi^2$-test on a cross-table

```{r, echo=T}
table(dat$group_2, dat$nominal_response)
```

<div class="fragment fade-in">
```{r, echo=T}
chisq.test(table(dat$group_2, dat$nominal_response))
```
</div>
</div>

## Binary response

<div style="width:30%;float:right;font-size:0.5em;">
```{r, echo = T, fig.height=4, fig.width = 4}
ggplot(dat, aes(group_2, fill = binary_response)) +
  geom_bar(color = "black")
```
</div>

<div style="width:70%;">
**Categorical explanatory with more than two categories**

Connection between variables can be tested with a $\chi^2$-test on a cross-table

```{r, echo=T}
table(dat$group_2, dat$binary_response)
```

<div class="fragment fade-in">
```{r, echo=T}
chisq.test(table(dat$group_1, dat$nominal_response))
```
</div>
</div>

## Binary response

<div style="width:30%;float:right;font-size:0.5em;">
```{r, echo = T, fig.height=4, fig.width = 4}
ggplot(dat, aes(group_1, fill = binary_response)) +
  geom_bar(color = "black")
```
</div>

<div style="width:70%;">
**Categorical explanatory with two categories**

Can be tested with a z-test

```{r, echo=T}
table(dat$group_1, dat$binary_response)
```

<div class="fragment fade-in">
```{r, echo=T}
prop.test(x = c(15,16), n = c(40, 40))
```
</div>
</div>

## Interval / ratio response

<div style="width:30%;float:right;font-size:0.5em;">
```{r, echo = T, fig.height=4, fig.width = 4}
ggplot(dat, aes(group_1, numeric_response)) +
  geom_point()
```
</div>

<div style="width:70%;">
**Categorical explanatory with two categories**

The two-sample t-test

Exact form depends on if data is paired or not

```{r, echo=T}
t.test(numeric_response ~ dat$group_1, dat)
```
</div>

##

<div style="width:30%;float:right;font-size:0.5em;">
```{r, echo = T, fig.height=4, fig.width = 4}
ggplot(dat, aes(group_2, numeric_response)) +
  geom_point()
```
</div>

<div style="width:70%;">
**Categorical explanatory with more than two categories**

F-test from an Anova model

```{r, echo=T}
mod <- lm(numeric_response ~ group_2, dat)
anova(mod)
```
</div>

##

Typically followed up with pairwise *post-hoc-tests*

```{r, echo=T}
library(emmeans)
emmeans(mod, pairwise ~ group_2)
```

## Interval / ratio response

<div style="width:30%;float:right;font-size:0.5em;">
```{r, echo = T, fig.height=4, fig.width = 4}
ggplot(dat, aes(numeric_explanatory, numeric_response)) +
  geom_point()
```
</div>

<div style="width:70%;">
**Numerical explanatory**

Connection between two numerical variables can be tested with correlation or regression

```{r, echo=T}
cor.test(dat$numeric_explanatory, 
         dat$numeric_response)
```
</div>

## 

Alternatively as a regression

```{r, echo=T}
mod <- lm(numeric_response ~ numeric_explanatory, dat)
anova(mod)
```

```{r, fig.align='center', fig.width=5, fig.height=5, echo=F}
ggplot(dat, aes(numeric_explanatory, numeric_response)) +
  geom_point() +
  geom_smooth(method = lm) +
  theme(axis.text = element_text(color = "white"),
        axis.title = element_text(color = "white"))
```

## Non-parametric methods

<div style="width:30%;float:right;font-size:0.5em;">
```{r, echo = T, fig.height=4, fig.width = 4}
ggplot(dat, aes(group_2, rank(numeric_response))) +
  geom_point()
```
</div>

<div style="width:70%;">
Non-parametric methods are used when distribution assumptions are not met

**Categorical explanatory**

A Kruskal-Wallis test for overall differences

```{r, echo=T}
kruskal.test(numeric_response ~ group_2, dat)
```

<div class="fragment fade-in">
Gives if there are *any* differences

Pairwise testing can be done with a *Dunn test* or repeated Kruskal-Wallis tests
</div>
</div>

##

<div style="width:30%;float:right;font-size:0.5em;">
```{r, echo = T, fig.height=4, fig.width = 4}
ggplot(dat, aes(rank(numeric_explanatory), 
                rank(numeric_response))) +
  geom_point()
```
</div>

<div style="width:70%;">
**Numerical explanatory**

The previously used correlation is the *Pearson* correlation

That test relies on an underlying normality assumption

*Spearman correlation* is a variant which drops that assumption

```{r, echo=T}
cor.test(dat$numeric_explanatory, 
         dat$numeric_response, 
         method = "spearman")
```
</div>

# Connections to linear models

Many basic tests are specific cases of *linear models*

A model where the response is the sum of additive terms

<div class="fragment fade-in">
Each term is an explanatory variable $x$ multiplied with some parameter $\beta$

$$y_i = \beta_0 + \beta_1 x_{1i} + ... + \beta_p x_{pi} + \varepsilon$$
</div>
<div class="fragment fade-in">
Direct examples are the Anova models and multiple regression models
</div>

## t-tests

A t-test comparing two groups (assuming equal variance) is equivalent to an Anova model

```{r, echo=T}
t.test(numeric_response ~ group_1, dat, var.equal = T)$p.value
```

<div class="fragment fade-in">
```{r, echo=T}
mod <- lm(numeric_response ~ group_1, dat)
anova(mod)
```
</div>

## Frequency tests

$\chi^2$-tests are equivalent to tests on a Poisson model, a kind of *GLM - generalized linear model*

```{r, echo=T}
chisq.test(table(dat$group_2, dat$nominal_response))$p.value
```

```{r, echo=T}
dat_freq <- dat %>% count(group_2, nominal_response)
mod <- glm(n ~ group_2 * nominal_response, dat_freq, family = "poisson")
anova(mod, test = "Rao")
```

## Non-parametric tests

Non-parametric tests are similar, but not equivalent, to standard tests on the *ranks* of the numerical values

The rank is the order number of the variable

<div class="fragment fade-in">
For an explanatory grouping

```{r, echo=T}
kruskal.test(numeric_response ~ group_1, dat)$p.value
```

```{r, echo=T}
t.test(rank(numeric_response) ~ group_1, dat)$p.value
```
</div>

##

For an explanatory numerical variable

Spearman correlation is the Pearson correlation between ranks

```{r, echo=T}
cor.test(dat$numeric_explanatory, dat$numeric_response, method = "spearman", exact = F)$p.value
```

```{r, echo=T}
cor.test(rank(dat$numeric_explanatory), rank(dat$numeric_response), method = "pearson")$p.value
```

# Additional resources

**Flowcharts**

https://guides.library.lincoln.ac.uk/mash/choosing_a_test

https://www.med.soton.ac.uk/resmethods/statisticalnotes/which_test_flow.htm

<br>

**Literature**

Thulin - *Modern Statistics with R* https://www.modernstatisticswithr.com/

Lindelöv - *Common statistical tests are linear models* https://lindeloev.github.io/tests-as-linear/

# The End

Thanks for your attention

<br>

3Bs will return in about two weeks